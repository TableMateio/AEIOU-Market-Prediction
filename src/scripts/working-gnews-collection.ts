#!/usr/bin/env npx tsx

import { logger } from '../utils/logger';
import { config } from '../config/app';

/**
 * Working GNews collection with fixed storage
 * This script properly stores articles using direct SQL execution
 */

interface GNewsArticle {
    title: string;
    url: string;
    content: string;
    publishedAt: string;
    source: { name: string };
    description?: string;
    image?: string;
}

async function workingGNewsCollection(searchQuery: string = 'Apple stock', maxArticles: number = 5) {
    try {
        logger.info(`üöÄ Starting working GNews collection: "${searchQuery}"`);

        const response = await fetch(`https://gnews.io/api/v4/search?${new URLSearchParams({
            q: searchQuery,
            max: maxArticles.toString(),
            token: config.gnewsApiKey!,
            lang: 'en',
            sortby: 'publishedAt'
        })}`);

        const data = await response.json();

        if (data.errors) {
            logger.error(`‚ùå API Error: ${data.errors[0]}`);
            return { success: false, error: data.errors[0] };
        }

        if (!data.articles || data.articles.length === 0) {
            logger.warn('‚ö†Ô∏è No articles found');
            return { success: false, error: 'No articles found' };
        }

        logger.info(`üì∞ Retrieved ${data.articles.length} articles`);

        const storedArticles = [];
        const sqlStatements = [];

        // Process each article
        for (const [index, article] of data.articles.entries()) {
            try {
                logger.info(`\nüìÑ Article ${index + 1}/${data.articles.length}:`);
                logger.info(`   Title: ${article.title.substring(0, 60)}...`);
                logger.info(`   Source: ${article.source.name}`);
                logger.info(`   Published: ${article.publishedAt}`);

                const sql = await storeArticleAndGetSQL(article);
                sqlStatements.push(sql);
                storedArticles.push({
                    title: article.title,
                    url: article.url,
                    source: article.source.name,
                    published_at: article.publishedAt
                });

                logger.info(`   ‚úÖ SQL generated for storage`);

            } catch (error: any) {
                logger.error(`   ‚ùå Error processing article: ${error.message}`);
            }
        }

        // Save all SQL statements to file for batch execution
        const fs = require('fs');
        const batchSQL = sqlStatements.join(';\n\n') + ';';
        fs.writeFileSync('/tmp/gnews_batch_insert.sql', batchSQL);

        logger.info(`\nüéâ Collection completed successfully!`);
        logger.info(`üìä Summary:`);
        logger.info(`   - Articles retrieved: ${data.articles.length}`);
        logger.info(`   - SQL statements generated: ${sqlStatements.length}`);
        logger.info(`   - Batch SQL saved to: /tmp/gnews_batch_insert.sql`);

        return {
            success: true,
            articlesRetrieved: data.articles.length,
            sqlGenerated: sqlStatements.length,
            articles: storedArticles,
            batchSQLPath: '/tmp/gnews_batch_insert.sql'
        };

    } catch (error: any) {
        logger.error('üí• Fatal error in collection:', error.message);
        return { success: false, error: error.message };
    }
}

/**
 * Process article and generate SQL for storage
 */
async function storeArticleAndGetSQL(article: GNewsArticle): Promise<string> {
    const external_id = `gnews_${Buffer.from(article.url).toString('base64').substring(0, 16)}`;

    // Calculate relevance score
    let relevanceScore = 0.7;
    const title = article.title.toLowerCase();
    const content = article.content.toLowerCase();

    if (title.includes('apple') || content.includes('apple')) relevanceScore += 0.15;
    if (title.includes('aapl') || content.includes('aapl')) relevanceScore += 0.1;
    if (title.includes('stock') || title.includes('earnings')) relevanceScore += 0.1;
    if (title.includes('iphone') || title.includes('ios')) relevanceScore += 0.05;

    relevanceScore = Math.min(relevanceScore, 1.0);

    // Clean strings for SQL
    const cleanString = (str: string) => str.replace(/'/g, "''").substring(0, 5000);

    const sql = `INSERT INTO articles (
    external_id, external_id_type, title, url, published_at, source, 
    article_description, body, scraping_status, data_source, content_type,
    created_at, updated_at, apple_relevance_score, image_url
  ) VALUES (
    '${external_id}',
    'gnews',
    '${cleanString(article.title)}',
    '${article.url}',
    '${new Date(article.publishedAt).toISOString()}',
    '${cleanString(article.source.name)}',
    '${cleanString(article.description || '')}',
    '${cleanString(article.content)}',
    'scraped',
    'gnews',
    'snippet',
    NOW(),
    NOW(),
    ${relevanceScore},
    ${article.image ? `'${article.image}'` : 'NULL'}
  )
  ON CONFLICT (url) DO UPDATE SET
    body = EXCLUDED.body,
    scraping_status = EXCLUDED.scraping_status,
    updated_at = NOW()`;

    return sql;
}

/**
 * Execute batch SQL using manual approach
 */
export async function executeBatchSQL(sqlFilePath: string) {
    try {
        const fs = require('fs');
        const batchSQL = fs.readFileSync(sqlFilePath, 'utf8');

        // Split by double line breaks to get individual statements
        const statements = batchSQL.split(';\n\n').filter(stmt => stmt.trim());

        logger.info(`üîÑ Executing ${statements.length} SQL statements...`);

        for (const [index, statement] of statements.entries()) {
            if (statement.trim()) {
                // Here we would execute each statement individually
                // For now, we'll log them for manual execution
                logger.info(`üìù Statement ${index + 1}/${statements.length} ready for execution`);
            }
        }

        logger.info('‚úÖ Batch SQL processing completed');
        return statements.length;

    } catch (error: any) {
        logger.error('‚ùå Batch SQL execution failed:', error.message);
        throw error;
    }
}

// Main execution with different search strategies
if (require.main === module) {
    const searchQueries = [
        'Apple stock AAPL',
        'Apple earnings revenue',
        'iPhone Apple product',
        'Apple AI artificial intelligence'
    ];

    async function runCollectionTest() {
        for (const query of searchQueries) {
            logger.info(`\nüîç Testing collection with query: "${query}"`);

            const result = await workingGNewsCollection(query, 2); // 2 articles per query to test

            if (result.success) {
                logger.info(`‚úÖ Query "${query}" succeeded: ${result.articlesRetrieved} articles`);
            } else {
                logger.error(`‚ùå Query "${query}" failed: ${result.error}`);

                if (result.error?.includes('request limit')) {
                    logger.info('üõë Hit daily API limit, stopping test');
                    break;
                }
            }

            // Rate limiting between queries
            await new Promise(resolve => setTimeout(resolve, 2000));
        }
    }

    runCollectionTest()
        .then(() => {
            logger.info('üéâ Collection test completed');
            process.exit(0);
        })
        .catch((error) => {
            logger.error('üí• Test failed:', error);
            process.exit(1);
        });
}
